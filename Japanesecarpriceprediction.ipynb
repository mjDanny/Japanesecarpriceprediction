{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.yandexcloud.net/academy.ai/japan_cars_dataset.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDCOnE5A7XiG",
        "outputId": "fbbf8471-6f16-4598-d5d8-5b2180620c58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-01 17:16:35--  https://storage.yandexcloud.net/academy.ai/japan_cars_dataset.csv\n",
            "Resolving storage.yandexcloud.net (storage.yandexcloud.net)... 213.180.193.243, 2a02:6b8::1d9\n",
            "Connecting to storage.yandexcloud.net (storage.yandexcloud.net)|213.180.193.243|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 136735 (134K) [text/csv]\n",
            "Saving to: ‘japan_cars_dataset.csv’\n",
            "\n",
            "japan_cars_dataset. 100%[===================>] 133.53K   204KB/s    in 0.7s    \n",
            "\n",
            "2024-06-01 17:16:37 (204 KB/s) - ‘japan_cars_dataset.csv’ saved [136735/136735]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "cars = pd.read_csv('japan_cars_dataset.csv', sep=',')\n",
        "\n",
        "# Удалим строки с пустыми значениями\n",
        "cars = cars.dropna()\n",
        "\n",
        "# Выводим первые 10 машин\n",
        "cars.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "NS_vFnv17mjE",
        "outputId": "cd9e2c71-859f-460d-804a-37752b028b86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  price        mark      model  year  mileage  engine_capacity  \\\n",
              "0           0     80      nissan      march  2003    80000             1240   \n",
              "1           1    110      nissan      march  2010    53000             1200   \n",
              "2           2    165      nissan    lafesta  2005    47690             2000   \n",
              "3           3    190      toyota    avensis  2008   130661             1990   \n",
              "4           4    190    daihatsu       mira  2006    66300              660   \n",
              "5           5    190    daihatsu       mira  2004    81400              660   \n",
              "6           8    220      nissan      march  2010   117000             1200   \n",
              "7           9    230  volkswagen     passat  2008   127763             3190   \n",
              "8          10    275       mazda  bongo van  2010   178218             1800   \n",
              "9          11    283       honda   step wgn  2005   121655             2000   \n",
              "\n",
              "  transmission drive hand_drive      fuel  \n",
              "0           at   2wd        rhd  gasoline  \n",
              "1           at   2wd        rhd  gasoline  \n",
              "2           at   2wd        rhd  gasoline  \n",
              "3           at   2wd        rhd  gasoline  \n",
              "4           at   2wd        rhd  gasoline  \n",
              "5           at   2wd        rhd  gasoline  \n",
              "6           at   2wd        rhd  gasoline  \n",
              "7           at   4wd        rhd  gasoline  \n",
              "8           mt   2wd        rhd  gasoline  \n",
              "9           at   2wd        rhd  gasoline  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bc555f5-9656-4706-a56b-38cc110ca814\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>price</th>\n",
              "      <th>mark</th>\n",
              "      <th>model</th>\n",
              "      <th>year</th>\n",
              "      <th>mileage</th>\n",
              "      <th>engine_capacity</th>\n",
              "      <th>transmission</th>\n",
              "      <th>drive</th>\n",
              "      <th>hand_drive</th>\n",
              "      <th>fuel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>nissan</td>\n",
              "      <td>march</td>\n",
              "      <td>2003</td>\n",
              "      <td>80000</td>\n",
              "      <td>1240</td>\n",
              "      <td>at</td>\n",
              "      <td>2wd</td>\n",
              "      <td>rhd</td>\n",
              "      <td>gasoline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>110</td>\n",
              "      <td>nissan</td>\n",
              "      <td>march</td>\n",
              "      <td>2010</td>\n",
              "      <td>53000</td>\n",
              "      <td>1200</td>\n",
              "      <td>at</td>\n",
              "      <td>2wd</td>\n",
              "      <td>rhd</td>\n",
              "      <td>gasoline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>165</td>\n",
              "      <td>nissan</td>\n",
              "      <td>lafesta</td>\n",
              "      <td>2005</td>\n",
              "      <td>47690</td>\n",
              "      <td>2000</td>\n",
              "      <td>at</td>\n",
              "      <td>2wd</td>\n",
              "      <td>rhd</td>\n",
              "      <td>gasoline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>190</td>\n",
              "      <td>toyota</td>\n",
              "      <td>avensis</td>\n",
              "      <td>2008</td>\n",
              "      <td>130661</td>\n",
              "      <td>1990</td>\n",
              "      <td>at</td>\n",
              "      <td>2wd</td>\n",
              "      <td>rhd</td>\n",
              "      <td>gasoline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>190</td>\n",
              "      <td>daihatsu</td>\n",
              "      <td>mira</td>\n",
              "      <td>2006</td>\n",
              "      <td>66300</td>\n",
              "      <td>660</td>\n",
              "      <td>at</td>\n",
              "      <td>2wd</td>\n",
              "      <td>rhd</td>\n",
              "      <td>gasoline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>190</td>\n",
              "      <td>daihatsu</td>\n",
              "      <td>mira</td>\n",
              "      <td>2004</td>\n",
              "      <td>81400</td>\n",
              "      <td>660</td>\n",
              "      <td>at</td>\n",
              "      <td>2wd</td>\n",
              "      <td>rhd</td>\n",
              "      <td>gasoline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8</td>\n",
              "      <td>220</td>\n",
              "      <td>nissan</td>\n",
              "      <td>march</td>\n",
              "      <td>2010</td>\n",
              "      <td>117000</td>\n",
              "      <td>1200</td>\n",
              "      <td>at</td>\n",
              "      <td>2wd</td>\n",
              "      <td>rhd</td>\n",
              "      <td>gasoline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>9</td>\n",
              "      <td>230</td>\n",
              "      <td>volkswagen</td>\n",
              "      <td>passat</td>\n",
              "      <td>2008</td>\n",
              "      <td>127763</td>\n",
              "      <td>3190</td>\n",
              "      <td>at</td>\n",
              "      <td>4wd</td>\n",
              "      <td>rhd</td>\n",
              "      <td>gasoline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10</td>\n",
              "      <td>275</td>\n",
              "      <td>mazda</td>\n",
              "      <td>bongo van</td>\n",
              "      <td>2010</td>\n",
              "      <td>178218</td>\n",
              "      <td>1800</td>\n",
              "      <td>mt</td>\n",
              "      <td>2wd</td>\n",
              "      <td>rhd</td>\n",
              "      <td>gasoline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11</td>\n",
              "      <td>283</td>\n",
              "      <td>honda</td>\n",
              "      <td>step wgn</td>\n",
              "      <td>2005</td>\n",
              "      <td>121655</td>\n",
              "      <td>2000</td>\n",
              "      <td>at</td>\n",
              "      <td>2wd</td>\n",
              "      <td>rhd</td>\n",
              "      <td>gasoline</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bc555f5-9656-4706-a56b-38cc110ca814')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9bc555f5-9656-4706-a56b-38cc110ca814 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9bc555f5-9656-4706-a56b-38cc110ca814');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f31672ed-4ec7-49ca-9427-9501ce3a53b5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f31672ed-4ec7-49ca-9427-9501ce3a53b5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f31672ed-4ec7-49ca-9427-9501ce3a53b5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cars",
              "summary": "{\n  \"name\": \"cars\",\n  \"rows\": 2318,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 674,\n        \"min\": 0,\n        \"max\": 2335,\n        \"num_unique_values\": 2318,\n        \"samples\": [\n          1050,\n          552,\n          102\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 288,\n        \"min\": 80,\n        \"max\": 1400,\n        \"num_unique_values\": 354,\n        \"samples\": [\n          1054,\n          467,\n          1236\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mark\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"mitsubishi\",\n          \"ford\",\n          \"kubota\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 258,\n        \"samples\": [\n          \"naked\",\n          \"esse\",\n          \"mercedes-benz others\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1979,\n        \"max\": 2015,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          1992,\n          2000,\n          1990\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mileage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52512,\n        \"min\": 2000,\n        \"max\": 790000,\n        \"num_unique_values\": 1367,\n        \"samples\": [\n          168000,\n          72867,\n          107915\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"engine_capacity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 549,\n        \"min\": 9,\n        \"max\": 12340,\n        \"num_unique_values\": 93,\n        \"samples\": [\n          3500,\n          2970,\n          2350\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transmission\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"at\",\n          \"mt\",\n          \"cvt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"drive\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2wd\",\n          \"4wd\",\n          \"awd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hand_drive\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"rhd\",\n          \"center\",\n          \"lhd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fuel\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"diesel\",\n          \"cng\",\n          \"hybrid\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, concatenate, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Загрузка данных\n",
        "cars = pd.read_csv('japan_cars_dataset.csv', sep=',')"
      ],
      "metadata": {
        "id": "bVGJ4Fn-61FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Удаление строк с пустыми значениями\n",
        "cars = cars.dropna()\n",
        "\n",
        "X = cars.drop('price', axis=1)\n",
        "y = cars['price']\n",
        "\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Разделение данных на обучающую, тестовую и проверочную выборки\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "gxmZ3YTb68sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Обработка числовых данных\n",
        "scaler = StandardScaler()\n",
        "X_train_num = scaler.fit_transform(X_train[numerical_features])\n",
        "X_test_num = scaler.transform(X_test[numerical_features])\n",
        "X_val_num = scaler.transform(X_val[numerical_features])\n",
        "\n",
        "# Обработка категориальных данных\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "X_train_cat = encoder.fit_transform(X_train[categorical_features])\n",
        "X_test_cat = encoder.transform(X_test[categorical_features])\n",
        "X_val_cat = encoder.transform(X_val[categorical_features])\n",
        "\n",
        "# Создание модели с двумя входами\n",
        "input_num = Input(shape=(X_train_num.shape[1],))\n",
        "input_cat = Input(shape=(X_train_cat.shape[1],))\n",
        "\n",
        "# Первый вход для числовых данных\n",
        "x1 = Dense(64, activation=\"relu\", kernel_regularizer=l2(0.001))(input_num)\n",
        "x1 = Dense(128, activation=\"relu\", kernel_regularizer=l2(0.001))(x1)\n",
        "x1 = Dense(256, activation=\"relu\", kernel_regularizer=l2(0.001))(x1)\n",
        "\n",
        "# Второй вход для категориальных данных\n",
        "x2 = Dense(64, activation=\"relu\", kernel_regularizer=l2(0.001))(input_cat)\n",
        "x2 = Dense(128, activation=\"relu\", kernel_regularizer=l2(0.001))(x2)\n",
        "x2 = Dropout(0.5)(x2)\n",
        "\n",
        "# Объединение двух веток\n",
        "x = concatenate([x1, x2])\n",
        "\n",
        "# Промежуточный слой\n",
        "x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Финальный регрессирующий нейрон\n",
        "output = Dense(1, activation='linear')(x)\n",
        "# В Model передаются входы и выход\n",
        "model = Model(inputs=[input_num, input_cat], outputs=output)\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "\n",
        "# Обучение модели\n",
        "history = model.fit([X_train_num, X_train_cat], y_train, epochs=200, batch_size=32, validation_data=([X_val_num, X_val_cat], y_val))\n",
        "\n",
        "# Оценка модели на тестовой выборке\n",
        "y_pred = model.predict([X_test_num, X_test_cat])\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f'Средняя квадратичная ошибка на тестовом наборе: {mse}')\n",
        "\n",
        "# Определение среднего процента ошибки на проверочной выборке\n",
        "percent_error = np.mean(np.abs((y_val - model.predict([X_val_num, X_val_cat]).flatten()) / y_val)) * 100\n",
        "print(f'Средняя процентная ошибка на валидационном множестве: {percent_error:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azZB5j8n4kqS",
        "outputId": "3e356206-13eb-4999-e96e-94b5b8c6372a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44/44 [==============================] - 2s 10ms/step - loss: 979895.6875 - val_loss: 695969.7500\n",
            "Epoch 2/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 285550.6250 - val_loss: 71327.3438\n",
            "Epoch 3/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 110622.7422 - val_loss: 34827.0234\n",
            "Epoch 4/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 72103.3984 - val_loss: 21973.9941\n",
            "Epoch 5/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 64024.2031 - val_loss: 17605.8242\n",
            "Epoch 6/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 54700.6289 - val_loss: 14560.9561\n",
            "Epoch 7/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 47884.0234 - val_loss: 11825.0850\n",
            "Epoch 8/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 49620.6484 - val_loss: 12378.4688\n",
            "Epoch 9/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 43986.7578 - val_loss: 13596.2480\n",
            "Epoch 10/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 45255.4609 - val_loss: 9163.3916\n",
            "Epoch 11/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 46771.7227 - val_loss: 12104.7432\n",
            "Epoch 12/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 40902.6758 - val_loss: 8517.4395\n",
            "Epoch 13/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 39202.6875 - val_loss: 9696.2305\n",
            "Epoch 14/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 40030.5508 - val_loss: 7199.8369\n",
            "Epoch 15/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 42243.7070 - val_loss: 9753.3252\n",
            "Epoch 16/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 39401.3828 - val_loss: 6225.3179\n",
            "Epoch 17/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 34566.1953 - val_loss: 6621.4497\n",
            "Epoch 18/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 36989.8203 - val_loss: 4316.4106\n",
            "Epoch 19/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 37310.1055 - val_loss: 4340.0020\n",
            "Epoch 20/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 35846.9766 - val_loss: 4463.1797\n",
            "Epoch 21/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 38331.7148 - val_loss: 5441.2344\n",
            "Epoch 22/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 34677.2578 - val_loss: 3272.3721\n",
            "Epoch 23/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 35069.1562 - val_loss: 4264.0107\n",
            "Epoch 24/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 34311.9961 - val_loss: 7798.9233\n",
            "Epoch 25/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 33997.6016 - val_loss: 2421.1736\n",
            "Epoch 26/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 34456.7930 - val_loss: 4587.3013\n",
            "Epoch 27/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 33662.6680 - val_loss: 1977.8701\n",
            "Epoch 28/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 36914.3086 - val_loss: 2157.2007\n",
            "Epoch 29/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 36451.0078 - val_loss: 1908.9299\n",
            "Epoch 30/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 36890.8789 - val_loss: 1783.3949\n",
            "Epoch 31/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 32991.1406 - val_loss: 3116.2527\n",
            "Epoch 32/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32639.2109 - val_loss: 2852.0054\n",
            "Epoch 33/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 35152.1250 - val_loss: 4056.2681\n",
            "Epoch 34/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 35487.2422 - val_loss: 1134.1190\n",
            "Epoch 35/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 29554.0664 - val_loss: 1406.1296\n",
            "Epoch 36/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 33674.3867 - val_loss: 1619.2373\n",
            "Epoch 37/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 34880.2773 - val_loss: 1218.3859\n",
            "Epoch 38/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 35376.5039 - val_loss: 2745.0251\n",
            "Epoch 39/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 33602.5000 - val_loss: 1613.1312\n",
            "Epoch 40/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32101.3184 - val_loss: 1070.9186\n",
            "Epoch 41/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32027.6289 - val_loss: 1350.4478\n",
            "Epoch 42/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32414.5215 - val_loss: 2631.9219\n",
            "Epoch 43/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30661.6172 - val_loss: 1317.6589\n",
            "Epoch 44/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 33142.1797 - val_loss: 3318.6689\n",
            "Epoch 45/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32899.8633 - val_loss: 2392.6775\n",
            "Epoch 46/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31340.0547 - val_loss: 2472.5349\n",
            "Epoch 47/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30383.5371 - val_loss: 2389.2874\n",
            "Epoch 48/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32423.1309 - val_loss: 1439.5668\n",
            "Epoch 49/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32579.7129 - val_loss: 1244.8147\n",
            "Epoch 50/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 35684.6250 - val_loss: 1198.5613\n",
            "Epoch 51/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32391.6309 - val_loss: 1299.7104\n",
            "Epoch 52/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32590.7305 - val_loss: 2925.0181\n",
            "Epoch 53/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31722.7852 - val_loss: 4102.5977\n",
            "Epoch 54/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32177.5156 - val_loss: 3090.1985\n",
            "Epoch 55/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 34091.4766 - val_loss: 1271.5856\n",
            "Epoch 56/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30774.4551 - val_loss: 1843.3372\n",
            "Epoch 57/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 29308.1719 - val_loss: 1780.9883\n",
            "Epoch 58/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 31341.1738 - val_loss: 1101.8422\n",
            "Epoch 59/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 33348.0117 - val_loss: 1549.2844\n",
            "Epoch 60/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 33124.2812 - val_loss: 3392.6460\n",
            "Epoch 61/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32735.3926 - val_loss: 729.8047\n",
            "Epoch 62/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 32810.4922 - val_loss: 1994.3618\n",
            "Epoch 63/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 33734.3906 - val_loss: 1740.3303\n",
            "Epoch 64/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31088.6738 - val_loss: 2637.6152\n",
            "Epoch 65/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 33259.0195 - val_loss: 1191.4612\n",
            "Epoch 66/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 32793.1602 - val_loss: 669.9872\n",
            "Epoch 67/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 33630.3867 - val_loss: 3244.6228\n",
            "Epoch 68/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 31753.4902 - val_loss: 1738.8632\n",
            "Epoch 69/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 31309.9316 - val_loss: 794.4574\n",
            "Epoch 70/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 34787.8203 - val_loss: 771.7988\n",
            "Epoch 71/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 32018.8984 - val_loss: 860.9540\n",
            "Epoch 72/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 31950.1562 - val_loss: 841.5464\n",
            "Epoch 73/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 30759.9648 - val_loss: 3271.1748\n",
            "Epoch 74/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 32739.6484 - val_loss: 1248.6469\n",
            "Epoch 75/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30363.0137 - val_loss: 1536.2045\n",
            "Epoch 76/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 33165.1641 - val_loss: 499.3363\n",
            "Epoch 77/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 33502.5234 - val_loss: 724.5209\n",
            "Epoch 78/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 33071.1055 - val_loss: 1308.0513\n",
            "Epoch 79/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 31493.6211 - val_loss: 3769.9578\n",
            "Epoch 80/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32234.5605 - val_loss: 1618.3071\n",
            "Epoch 81/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31594.1895 - val_loss: 632.1374\n",
            "Epoch 82/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 33407.6680 - val_loss: 2199.6519\n",
            "Epoch 83/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 32287.9922 - val_loss: 864.9464\n",
            "Epoch 84/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32118.3145 - val_loss: 701.1874\n",
            "Epoch 85/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31969.3418 - val_loss: 1698.2747\n",
            "Epoch 86/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32317.1602 - val_loss: 1583.1499\n",
            "Epoch 87/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30977.1348 - val_loss: 2132.0510\n",
            "Epoch 88/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 29775.2461 - val_loss: 6975.6323\n",
            "Epoch 89/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 29795.3008 - val_loss: 797.9044\n",
            "Epoch 90/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32444.4062 - val_loss: 2003.5145\n",
            "Epoch 91/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32698.6855 - val_loss: 2210.4685\n",
            "Epoch 92/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 34148.2070 - val_loss: 848.6962\n",
            "Epoch 93/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32218.1152 - val_loss: 2934.4734\n",
            "Epoch 94/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 31389.6172 - val_loss: 478.0682\n",
            "Epoch 95/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31255.9258 - val_loss: 4947.1284\n",
            "Epoch 96/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 33793.7227 - val_loss: 3401.0308\n",
            "Epoch 97/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 32116.6133 - val_loss: 1418.7821\n",
            "Epoch 98/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 29946.3223 - val_loss: 2324.4412\n",
            "Epoch 99/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30720.7676 - val_loss: 1597.0675\n",
            "Epoch 100/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 31830.7285 - val_loss: 1009.7336\n",
            "Epoch 101/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30990.6484 - val_loss: 469.6045\n",
            "Epoch 102/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32794.0703 - val_loss: 582.7799\n",
            "Epoch 103/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32259.3848 - val_loss: 564.1733\n",
            "Epoch 104/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31922.5000 - val_loss: 1752.1676\n",
            "Epoch 105/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 34727.3789 - val_loss: 1534.2374\n",
            "Epoch 106/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31459.4062 - val_loss: 1425.6521\n",
            "Epoch 107/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 31008.2754 - val_loss: 621.4435\n",
            "Epoch 108/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 33082.0938 - val_loss: 475.5598\n",
            "Epoch 109/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 33084.0898 - val_loss: 619.0591\n",
            "Epoch 110/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 31379.8848 - val_loss: 951.1803\n",
            "Epoch 111/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 33491.4102 - val_loss: 580.3140\n",
            "Epoch 112/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 33711.2305 - val_loss: 1975.4866\n",
            "Epoch 113/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 33571.9961 - val_loss: 1162.8975\n",
            "Epoch 114/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 33539.7930 - val_loss: 2206.0381\n",
            "Epoch 115/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 30139.9941 - val_loss: 916.3495\n",
            "Epoch 116/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 30466.0195 - val_loss: 2703.9561\n",
            "Epoch 117/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 30278.2422 - val_loss: 554.0698\n",
            "Epoch 118/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 33963.7305 - val_loss: 636.1429\n",
            "Epoch 119/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30503.7988 - val_loss: 1038.8962\n",
            "Epoch 120/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 29756.8633 - val_loss: 1752.3541\n",
            "Epoch 121/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32193.3906 - val_loss: 1142.9460\n",
            "Epoch 122/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 32365.9805 - val_loss: 778.2717\n",
            "Epoch 123/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30569.9043 - val_loss: 479.9987\n",
            "Epoch 124/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32989.7656 - val_loss: 503.7601\n",
            "Epoch 125/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31738.5547 - val_loss: 1734.1130\n",
            "Epoch 126/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 31458.0195 - val_loss: 1819.8972\n",
            "Epoch 127/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32534.3945 - val_loss: 2909.7600\n",
            "Epoch 128/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 30339.9648 - val_loss: 1123.5372\n",
            "Epoch 129/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30136.2656 - val_loss: 1908.5256\n",
            "Epoch 130/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31326.0801 - val_loss: 1945.6508\n",
            "Epoch 131/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32216.6816 - val_loss: 1046.7119\n",
            "Epoch 132/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31504.4316 - val_loss: 923.0369\n",
            "Epoch 133/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 31945.7930 - val_loss: 3576.7983\n",
            "Epoch 134/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 33349.2422 - val_loss: 2913.5056\n",
            "Epoch 135/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 30270.2051 - val_loss: 6608.4580\n",
            "Epoch 136/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 33032.4102 - val_loss: 4069.8506\n",
            "Epoch 137/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32258.0957 - val_loss: 1909.2080\n",
            "Epoch 138/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 30511.2578 - val_loss: 1013.7246\n",
            "Epoch 139/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30499.0957 - val_loss: 723.3553\n",
            "Epoch 140/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 33082.8047 - val_loss: 2294.0515\n",
            "Epoch 141/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 33259.1992 - val_loss: 2343.4321\n",
            "Epoch 142/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32435.8301 - val_loss: 323.5733\n",
            "Epoch 143/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 33004.1484 - val_loss: 2810.5249\n",
            "Epoch 144/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 31922.9297 - val_loss: 2158.6479\n",
            "Epoch 145/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30509.0156 - val_loss: 423.5489\n",
            "Epoch 146/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31275.7012 - val_loss: 689.3671\n",
            "Epoch 147/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 32604.6641 - val_loss: 843.1171\n",
            "Epoch 148/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30948.8496 - val_loss: 734.4210\n",
            "Epoch 149/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30818.6211 - val_loss: 2060.8508\n",
            "Epoch 150/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 29138.8633 - val_loss: 1798.1772\n",
            "Epoch 151/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 31148.5527 - val_loss: 527.9904\n",
            "Epoch 152/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 34959.2422 - val_loss: 2540.6179\n",
            "Epoch 153/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 29678.0801 - val_loss: 974.5029\n",
            "Epoch 154/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 33488.7266 - val_loss: 6971.6821\n",
            "Epoch 155/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31364.3301 - val_loss: 6002.3286\n",
            "Epoch 156/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 30968.7051 - val_loss: 2435.4331\n",
            "Epoch 157/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 31977.5801 - val_loss: 3972.8916\n",
            "Epoch 158/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 30675.1348 - val_loss: 3187.7500\n",
            "Epoch 159/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 33954.4375 - val_loss: 585.3319\n",
            "Epoch 160/200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 31202.2363 - val_loss: 416.0862\n",
            "Epoch 161/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 29769.4238 - val_loss: 507.9170\n",
            "Epoch 162/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 30639.6484 - val_loss: 463.4633\n",
            "Epoch 163/200\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 30932.0742 - val_loss: 2271.0491\n",
            "Epoch 164/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 33638.8438 - val_loss: 2307.4451\n",
            "Epoch 165/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32196.6074 - val_loss: 3202.8999\n",
            "Epoch 166/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31534.2266 - val_loss: 3211.6331\n",
            "Epoch 167/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31780.5762 - val_loss: 2444.5906\n",
            "Epoch 168/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30955.6094 - val_loss: 861.9184\n",
            "Epoch 169/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30501.7324 - val_loss: 2687.4712\n",
            "Epoch 170/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 29996.0781 - val_loss: 1426.9672\n",
            "Epoch 171/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 30182.7520 - val_loss: 2204.2612\n",
            "Epoch 172/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32287.4824 - val_loss: 1467.9723\n",
            "Epoch 173/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31426.8555 - val_loss: 1466.8950\n",
            "Epoch 174/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31706.3828 - val_loss: 3005.2012\n",
            "Epoch 175/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31535.2578 - val_loss: 2928.9956\n",
            "Epoch 176/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 31535.6406 - val_loss: 362.9803\n",
            "Epoch 177/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 34326.0195 - val_loss: 1149.7588\n",
            "Epoch 178/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31271.3496 - val_loss: 2474.5479\n",
            "Epoch 179/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31864.3535 - val_loss: 958.4750\n",
            "Epoch 180/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30709.7500 - val_loss: 3265.7688\n",
            "Epoch 181/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31686.0254 - val_loss: 2062.2041\n",
            "Epoch 182/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 33110.6758 - val_loss: 5991.1602\n",
            "Epoch 183/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30701.0840 - val_loss: 1133.5758\n",
            "Epoch 184/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 32627.0508 - val_loss: 215.6108\n",
            "Epoch 185/200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 31728.1523 - val_loss: 1838.2889\n",
            "Epoch 186/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 29689.9707 - val_loss: 1739.3733\n",
            "Epoch 187/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 33867.6953 - val_loss: 2827.3350\n",
            "Epoch 188/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 33914.1641 - val_loss: 398.8210\n",
            "Epoch 189/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 32239.4062 - val_loss: 4598.9854\n",
            "Epoch 190/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31936.1113 - val_loss: 443.0796\n",
            "Epoch 191/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 33383.3477 - val_loss: 1081.5089\n",
            "Epoch 192/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30355.0879 - val_loss: 1685.7458\n",
            "Epoch 193/200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 31092.7852 - val_loss: 1267.3243\n",
            "Epoch 194/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31059.4883 - val_loss: 4460.0869\n",
            "Epoch 195/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 31176.3906 - val_loss: 290.1377\n",
            "Epoch 196/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 35539.6758 - val_loss: 726.9162\n",
            "Epoch 197/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 30126.5391 - val_loss: 909.2035\n",
            "Epoch 198/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 29355.9023 - val_loss: 238.2992\n",
            "Epoch 199/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 29271.0332 - val_loss: 3648.9968\n",
            "Epoch 200/200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 34363.1758 - val_loss: 2355.3669\n",
            "15/15 [==============================] - 0s 3ms/step\n",
            "Средняя квадратичная ошибка на тестовом наборе: 2615.085903038397\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "Средняя процентная ошибка на валидационном множестве: 4.41%\n"
          ]
        }
      ]
    }
  ]
}